# FastAPI Data Science - Projet Fil Rouge

ğŸ“ **Projet pÃ©dagogique** : API FastAPI pour un parcours complet Data Scientist en 5 phases

---

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Architecture](#architecture)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Les 5 Phases du Projet](#les-5-phases-du-projet)
- [Endpoints](#endpoints)
- [Tests](#tests)
- [Structure du Projet](#structure-du-projet)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente une API complÃ¨te couvrant l'ensemble du cycle de vie d'un projet Data Science :

1. **TP1 - Clean** : Nettoyage et prÃ©paration des donnÃ©es
2. **TP2 - EDA** : Analyse exploratoire et visualisations
3. **TP3 - MV** : Analyse multivariÃ©e (PCA, Clustering)
4. **TP4 - ML** : Machine Learning baseline
5. **TP5 - ML2** : ML avancÃ© (tuning, explicabilitÃ©)

### âœ¨ CaractÃ©ristiques

- âœ… GÃ©nÃ©ration automatique de datasets reproductibles
- âœ… API RESTful complÃ¨te avec FastAPI
- âœ… Validation des donnÃ©es avec Pydantic
- âœ… Documentation interactive Swagger (/docs)
- âœ… Architecture modulaire (routers/services/schemas)
- âœ… DockerisÃ© pour un dÃ©ploiement facile
- âœ… Sans base de donnÃ©es (stockage en mÃ©moire)
- âœ… Notebooks Jupyter pour dÃ©monstration

---

## ğŸ—ï¸ Architecture

```
fastapi-ds-project/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ routers/             # Endpoints par phase
â”‚   â”‚   â”œâ”€â”€ dataset.py       # GÃ©nÃ©ration datasets
â”‚   â”‚   â”œâ”€â”€ clean.py         # TP1 - Nettoyage
â”‚   â”‚   â”œâ”€â”€ eda.py           # TP2 - EDA
â”‚   â”‚   â”œâ”€â”€ mv.py            # TP3 - MultivariÃ©
â”‚   â”‚   â”œâ”€â”€ ml.py            # TP4 - ML Baseline
â”‚   â”‚   â””â”€â”€ ml2.py           # TP5 - ML AvancÃ©
â”‚   â”œâ”€â”€ services/            # Logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ dataset_generator.py
â”‚   â”‚   â”œâ”€â”€ cleaning_service.py
â”‚   â”‚   â”œâ”€â”€ eda_service.py
â”‚   â”‚   â”œâ”€â”€ mv_service.py
â”‚   â”‚   â”œâ”€â”€ ml_service.py
â”‚   â”‚   â””â”€â”€ ml2_service.py
â”‚   â”œâ”€â”€ schemas/             # ModÃ¨les Pydantic
â”‚   â”‚   â””â”€â”€ common.py
â”‚   â””â”€â”€ models/              # Stockage modÃ¨les
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ demo_tp1_clean.ipynb
â”‚   â”œâ”€â”€ demo_tp2_eda.ipynb
â”‚   â”œâ”€â”€ demo_tp3_mv.ipynb
â”‚   â”œâ”€â”€ demo_tp4_ml.ipynb
â”‚   â””â”€â”€ demo_tp5_ml2.ipynb
â”œâ”€â”€ tests/                   # Tests unitaires
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Principes architecturaux

1. **SÃ©paration des responsabilitÃ©s** : 
   - Routers â†’ gÃ¨rent les requÃªtes HTTP
   - Services â†’ contiennent la logique mÃ©tier
   - Schemas â†’ validation des donnÃ©es

2. **Contrat API standardisÃ©** :
   - Request : `{meta, data, params}`
   - Response : `{meta, result, report, artifacts}`

3. **ReproductibilitÃ©** : mÃªme `seed` â†’ mÃªme dataset

---

## ğŸš€ Installation

### PrÃ©requis

- Docker et Docker Compose
- Ou Python 3.9+

### Option 1 : Avec Docker (recommandÃ©)

```bash
# 1. Cloner le projet
git clone <votre-repo>
cd fastapi-ds-project

# 2. Lancer avec Docker Compose
docker-compose up --build

# L'API sera accessible sur http://localhost:8000
# Documentation : http://localhost:8000/docs
```

### Option 2 : Sans Docker

```bash
# 1. CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# 2. Installer les dÃ©pendances
pip install -r requirements.txt

# 3. Lancer l'API
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Option 3 : Avec Jupyter (pour les notebooks)

```bash
# Installer Jupyter
pip install jupyter

# Lancer Jupyter
jupyter notebook

# Ouvrir les notebooks dans notebooks/
```

---

## ğŸ“– Utilisation

### 1. AccÃ©der Ã  la documentation interactive

Ouvrez votre navigateur : **http://localhost:8000/docs**

Vous verrez l'interface Swagger avec tous les endpoints testables.

### 2. Workflow typique

#### Ã‰tape 1 : GÃ©nÃ©rer un dataset

```bash
curl -X POST "http://localhost:8000/dataset/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "phase": "clean",
    "seed": 42,
    "n": 1000
  }'
```

RÃ©ponse :
```json
{
  "meta": {
    "dataset_id": "clean_42_1000",
    "schema_version": "1.0"
  },
  "result": {
    "columns": ["x1", "x2", "x3", "segment", "target"],
    "data_sample": [...]
  }
}
```

#### Ã‰tape 2 : Utiliser le dataset_id dans les endpoints de phase

Exemple pour TP1 (Clean) :
```bash
curl -X POST "http://localhost:8000/clean/fit" \
  -H "Content-Type: application/json" \
  -d '{
    "meta": {
      "dataset_id": "clean_42_1000"
    },
    "params": {
      "impute_strategy": "mean",
      "outlier_strategy": "clip",
      "categorical_strategy": "one_hot"
    }
  }'
```

---

## ğŸ“ Les 5 Phases du Projet

### TP1 - Clean : Nettoyage des DonnÃ©es

**Objectif** : Transformer des donnÃ©es sales en donnÃ©es propres

**DÃ©fauts traitÃ©s** :
- âŒ Valeurs manquantes (10-20%)
- âŒ Doublons (1-5%)
- âŒ Outliers (1-3%)
- âŒ Types incohÃ©rents

**Endpoints** :
- `POST /dataset/generate` - GÃ©nÃ©rer dataset avec dÃ©fauts
- `POST /clean/fit` - Apprendre pipeline de nettoyage
- `POST /clean/transform` - Appliquer le nettoyage
- `GET /clean/report/{dataset_id}` - Rapport qualitÃ©

---

### TP2 - EDA : Analyse Exploratoire

**Objectif** : Produire statistiques et graphiques sans notebook

**FonctionnalitÃ©s** :
- ğŸ“Š Statistiques descriptives
- ğŸ“ˆ Graphiques interactifs (Plotly)
- ğŸ”— CorrÃ©lations
- ğŸ“¦ AgrÃ©gations par groupe

**Endpoints** :
- `POST /eda/summary` - Stats par variable
- `POST /eda/groupby` - AgrÃ©gations
- `POST /eda/correlation` - Matrice de corrÃ©lation
- `POST /eda/plots` - GÃ©nÃ©rer graphiques

---

### TP3 - MV : Analyse MultivariÃ©e

**Objectif** : PCA et Clustering avec rÃ©sultats interprÃ©tables

**MÃ©thodes** :
- ğŸ¯ PCA (rÃ©duction dimensionnelle)
- ğŸ” K-Means clustering
- ğŸ“Š Loadings et explained variance

**Endpoints** :
- `POST /mv/pca/fit_transform` - PCA avec projections
- `POST /mv/cluster/kmeans` - Clustering K-Means
- `GET /mv/report/{dataset_id}` - Rapport interprÃ©tatif

---

### TP4 - ML : Machine Learning Baseline

**Objectif** : EntraÃ®ner, Ã©valuer, prÃ©dire avec modÃ¨les supervisÃ©s

**ModÃ¨les** :
- ğŸ“‰ Logistic Regression
- ğŸŒ² Random Forest

**Endpoints** :
- `POST /ml/train` - EntraÃ®ner un modÃ¨le
- `GET /ml/metrics/{model_id}` - MÃ©triques de performance
- `POST /ml/predict` - Faire des prÃ©dictions
- `GET /ml/model-info/{model_id}` - Infos du modÃ¨le

---

### TP5 - ML2 : ML AvancÃ©

**Objectif** : Optimisation et explicabilitÃ©

**FonctionnalitÃ©s** :
- ğŸ¯ Hyperparameter tuning (Grid/Random Search)
- ğŸ“Š Feature importance
- ğŸ” Permutation importance
- ğŸ’¡ Explications locales

**Endpoints** :
- `POST /ml2/tune` - Tuning avec CV
- `GET /ml2/feature-importance/{model_id}` - Importance des features
- `POST /ml2/permutation-importance` - Importance par permutation
- `POST /ml2/explain-instance` - Explication locale

---

## ğŸ”Œ Endpoints

### GÃ©nÃ©ration de Datasets

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| POST | `/dataset/generate` | GÃ©nÃ¨re un dataset pour une phase donnÃ©e |

### TP1 - Clean

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| POST | `/clean/fit` | Apprend un pipeline de nettoyage |
| POST | `/clean/transform` | Applique le nettoyage |
| GET | `/clean/report/{dataset_id}` | Rapport qualitÃ© |

### TP2 - EDA

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| POST | `/eda/summary` | Statistiques descriptives |
| POST | `/eda/groupby` | AgrÃ©gations par groupe |
| POST | `/eda/correlation` | Matrice de corrÃ©lation |
| POST | `/eda/plots` | GÃ©nÃ¨re graphiques |

### TP3 - MV

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| POST | `/mv/pca/fit_transform` | PCA avec projections |
| POST | `/mv/cluster/kmeans` | Clustering K-Means |
| GET | `/mv/report/{dataset_id}` | Rapport interprÃ©tatif |

### TP4 - ML

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| POST | `/ml/train` | EntraÃ®ne un modÃ¨le |
| GET | `/ml/metrics/{model_id}` | MÃ©triques |
| POST | `/ml/predict` | PrÃ©dictions |
| GET | `/ml/model-info/{model_id}` | Infos modÃ¨le |

### TP5 - ML2

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| POST | `/ml2/tune` | Tuning avec CV |
| GET | `/ml2/feature-importance/{model_id}` | Feature importance |
| POST | `/ml2/permutation-importance` | Permutation importance |
| POST | `/ml2/explain-instance` | Explication locale |

---

## ğŸ§ª Tests

```bash
# Lancer les tests
pytest tests/

# Avec couverture
pytest --cov=app tests/
```

---

## ğŸ“Š Exemples de Notebooks

Les notebooks dans `notebooks/` dÃ©montrent l'utilisation complÃ¨te de l'API pour chaque TP :

1. **demo_tp1_clean.ipynb** : Nettoyage de donnÃ©es
2. **demo_tp2_eda.ipynb** : Analyse exploratoire
3. **demo_tp3_mv.ipynb** : PCA et Clustering
4. **demo_tp4_ml.ipynb** : Machine Learning baseline
5. **demo_tp5_ml2.ipynb** : ML avancÃ© avec tuning

---

## ğŸ› ï¸ Technologies UtilisÃ©es

- **FastAPI** : Framework web moderne et rapide
- **Pydantic** : Validation de donnÃ©es
- **Pandas** : Manipulation de donnÃ©es
- **NumPy** : Calculs numÃ©riques
- **Scikit-learn** : Machine Learning
- **Plotly** : Visualisations interactives
- **Docker** : Containerisation

---

## ğŸ“ Licence

Projet pÃ©dagogique - Ayedesso - 2026

---

## ğŸ‘¥ Auteur

**Ayedesso**  
Projet fil rouge FastAPI - Parcours Data Scientist

---

## ğŸ†˜ Support

Pour toute question :
1. Consultez la documentation interactive : `/docs`
2. VÃ©rifiez les notebooks de dÃ©monstration
3. Consultez les tests pour des exemples d'utilisation

---

**Bon dÃ©veloppement ! ğŸš€**
