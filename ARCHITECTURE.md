# ğŸ—ï¸ Architecture du Projet

Ce document explique l'architecture et les principes de conception du projet.

---

## ğŸ“ Vue d'ensemble

Le projet suit une **architecture en couches** classique pour les APIs REST :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Clients (HTTP Requests)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Routers (FastAPI Endpoints)          â”‚
â”‚   - Validation des requÃªtes (Pydantic)     â”‚
â”‚   - Gestion des erreurs HTTP                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Services (Logique MÃ©tier)          â”‚
â”‚   - Algorithmes data science                â”‚
â”‚   - Transformations                         â”‚
â”‚   - ML pipelines                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Stockage (In-Memory Dictionaries)      â”‚
â”‚   - Datasets                                â”‚
â”‚   - Cleaners                                â”‚
â”‚   - ModÃ¨les ML                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Structure des Dossiers

```
fastapi-ds-project/
â”‚
â”œâ”€â”€ app/                          # Code source de l'application
â”‚   â”œâ”€â”€ main.py                   # Point d'entrÃ©e FastAPI
â”‚   â”‚
â”‚   â”œâ”€â”€ routers/                  # Couche de routage (endpoints)
â”‚   â”‚   â”œâ”€â”€ dataset.py            # GÃ©nÃ©ration datasets
â”‚   â”‚   â”œâ”€â”€ clean.py              # TP1 - Clean
â”‚   â”‚   â”œâ”€â”€ eda.py                # TP2 - EDA
â”‚   â”‚   â”œâ”€â”€ mv.py                 # TP3 - MultivariÃ©
â”‚   â”‚   â”œâ”€â”€ ml.py                 # TP4 - ML
â”‚   â”‚   â””â”€â”€ ml2.py                # TP5 - ML2
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                 # Couche de logique mÃ©tier
â”‚   â”‚   â”œâ”€â”€ dataset_generator.py  # GÃ©nÃ©ration de datasets
â”‚   â”‚   â”œâ”€â”€ cleaning_service.py   # Nettoyage de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ eda_service.py        # Analyse exploratoire
â”‚   â”‚   â”œâ”€â”€ mv_service.py         # PCA, Clustering
â”‚   â”‚   â”œâ”€â”€ ml_service.py         # ML baseline
â”‚   â”‚   â””â”€â”€ ml2_service.py        # ML avancÃ©
â”‚   â”‚
â”‚   â””â”€â”€ schemas/                  # ModÃ¨les Pydantic
â”‚       â””â”€â”€ common.py             # SchÃ©mas partagÃ©s
â”‚
â”œâ”€â”€ notebooks/                    # Notebooks de dÃ©monstration
â”‚   â”œâ”€â”€ demo_tp1_clean.ipynb
â”‚   â”œâ”€â”€ demo_tp2_eda.ipynb
â”‚   â”œâ”€â”€ demo_tp3_mv.ipynb
â”‚   â”œâ”€â”€ demo_tp4_ml.ipynb
â”‚   â””â”€â”€ demo_tp5_ml2.ipynb
â”‚
â”œâ”€â”€ tests/                        # Tests unitaires
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ models/                       # Stockage modÃ¨les (vide au dÃ©part)
â”œâ”€â”€ data/                         # DonnÃ©es (vide au dÃ©part)
â”‚
â”œâ”€â”€ Dockerfile                    # Image Docker
â”œâ”€â”€ docker-compose.yml            # Orchestration
â”œâ”€â”€ requirements.txt              # DÃ©pendances Python
â””â”€â”€ README.md                     # Documentation principale
```

---

## ğŸ¯ Principes de Conception

### 1. SÃ©paration des ResponsabilitÃ©s

**Routers** (couche prÃ©sentation)
- GÃ¨rent les requÃªtes/rÃ©ponses HTTP
- Validation des entrÃ©es avec Pydantic
- Gestion des erreurs (try/catch â†’ HTTPException)
- **NE CONTIENNENT PAS** de logique mÃ©tier

**Services** (couche mÃ©tier)
- Contiennent toute la logique data science
- IndÃ©pendants de FastAPI (peuvent Ãªtre rÃ©utilisÃ©s ailleurs)
- Retournent des structures Python natives (dict, DataFrame)

**Schemas** (modÃ¨les de donnÃ©es)
- Validation automatique avec Pydantic
- Documentation automatique dans Swagger
- Type safety

### 2. Contrat API StandardisÃ©

Toutes les requÃªtes/rÃ©ponses suivent la mÃªme structure :

**Request** :
```json
{
  "meta": {
    "dataset_id": "...",
    "schema_version": "1.0"
  },
  "data": [...],      // Optionnel
  "params": {...}     // Optionnel
}
```

**Response** :
```json
{
  "meta": {
    "dataset_id": "...",
    "schema_version": "1.0"
  },
  "result": {...},    // RÃ©sultat principal
  "report": {...},    // Statistiques/mÃ©triques
  "artifacts": {...}  // Graphiques, modÃ¨les, etc.
}
```

### 3. ReproductibilitÃ©

- **Datasets** : MÃªme `seed` â†’ MÃªme dataset
- **Identifiants** : `dataset_id = f"{phase}_{seed}_{n}"`
- **Stockage en mÃ©moire** : Permet de rÃ©utiliser les datasets entre endpoints

### 4. Sans Base de DonnÃ©es

- **Stockage** : Dictionnaires Python en mÃ©moire
- **Avantages** :
  - SimplicitÃ© (pas de setup DB)
  - RapiditÃ© de dÃ©veloppement
  - IdÃ©al pour prototypage/dÃ©monstration
- **Limitations** :
  - DonnÃ©es perdues au redÃ©marrage
  - Non adaptÃ© pour production Ã  grande Ã©chelle

---

## ğŸ”„ Flux de DonnÃ©es Typique

### Exemple : TP1 - Clean

```
1. Client envoie POST /dataset/generate
   â†“
2. Router dataset.py valide la requÃªte
   â†“
3. Service DatasetGenerator.generate()
   - GÃ©nÃ¨re un DataFrame avec dÃ©fauts
   - Stocke dans _datasets dict
   â†“
4. Router retourne dataset_id + Ã©chantillon
   â†“
5. Client envoie POST /clean/fit avec dataset_id
   â†“
6. Router clean.py rÃ©cupÃ¨re le dataset
   â†“
7. Service CleaningService.fit()
   - Analyse les donnÃ©es
   - Apprend les rÃ¨gles de nettoyage
   - Retourne cleaner_id + rÃ¨gles
   â†“
8. Client envoie POST /clean/transform
   â†“
9. Service CleaningService.transform()
   - Applique les rÃ¨gles
   - Retourne donnÃ©es nettoyÃ©es + rapport
```

---

## ğŸ§© Modules ClÃ©s

### dataset_generator.py

**ResponsabilitÃ©** : GÃ©nÃ©rer des datasets reproductibles

**Fonctions principales** :
- `generate(phase, seed, n)` â†’ GÃ©nÃ¨re un dataset
- `get_dataset(dataset_id)` â†’ RÃ©cupÃ¨re un dataset existant

**Stockage** :
```python
_datasets: Dict[str, pd.DataFrame] = {}
```

### cleaning_service.py (TP1)

**ResponsabilitÃ©** : Nettoyage de donnÃ©es

**Fonctions principales** :
- `generate_report(df)` â†’ Analyse qualitÃ©
- `fit(df, params)` â†’ Apprend pipeline de nettoyage
- `transform(df, cleaner_data)` â†’ Applique le nettoyage

**Traite** :
- Missing values (imputation)
- Doublons (suppression)
- Outliers (clip ou remove)
- Types cassÃ©s (conversion)
- Variables catÃ©gorielles (encoding)

### eda_service.py (TP2)

**ResponsabilitÃ©** : Analyse exploratoire

**Fonctions principales** :
- `summary(df)` â†’ Statistiques descriptives
- `groupby(df, by, metrics)` â†’ AgrÃ©gations
- `correlation(df)` â†’ Matrice de corrÃ©lation
- `plots(df)` â†’ Graphiques Plotly (JSON)

### mv_service.py (TP3)

**ResponsabilitÃ©** : Analyse multivariÃ©e

**Fonctions principales** :
- `pca_fit_transform(df, n_components, scale)` â†’ PCA avec loadings
- `cluster_kmeans(df, k, scale)` â†’ Clustering K-Means
- `generate_report(df)` â†’ Rapport interprÃ©tatif

### ml_service.py (TP4)

**ResponsabilitÃ©** : ML baseline

**Fonctions principales** :
- `train(df, model_type)` â†’ EntraÃ®ne LogReg ou RF
- `predict(model_data, X)` â†’ PrÃ©dictions
- `get_model_info(model_data)` â†’ Infos modÃ¨le

**Stockage** :
```python
_models: Dict[str, Dict[str, Any]] = {}
```

### ml2_service.py (TP5)

**ResponsabilitÃ©** : ML avancÃ©

**Fonctions principales** :
- `tune_model(df, model_type, search, cv)` â†’ Hyperparameter tuning
- `feature_importance(model_data)` â†’ Importance native
- `permutation_importance_analysis()` â†’ Importance par permutation
- `explain_instance(model_data, instance)` â†’ Explication locale

---

## ğŸ” Validation et Gestion d'Erreurs

### Validation des EntrÃ©es

Toutes les entrÃ©es sont validÃ©es par **Pydantic** :

```python
class DatasetGenerateRequest(BaseModel):
    phase: str
    seed: int
    n: int = Field(..., gt=0)  # n doit Ãªtre > 0
```

Si validation Ã©choue â†’ **422 Unprocessable Entity**

### Gestion d'Erreurs

Pattern utilisÃ© dans tous les routers :

```python
try:
    # Logique mÃ©tier
    result = service.do_something()
    return StandardResponse(...)
except Exception as e:
    raise HTTPException(status_code=400, detail=str(e))
```

Codes HTTP utilisÃ©s :
- **200** : SuccÃ¨s
- **400** : Erreur client (paramÃ¨tres invalides)
- **404** : Ressource introuvable (dataset_id, model_id)
- **422** : Validation Pydantic Ã©chouÃ©e

---

## ğŸš€ ExtensibilitÃ©

### Ajouter une Nouvelle Phase

1. **CrÃ©er un service** dans `app/services/`
2. **CrÃ©er un router** dans `app/routers/`
3. **Enregistrer le router** dans `app/main.py` :
   ```python
   app.include_router(new_phase.router, prefix="/new", tags=["New Phase"])
   ```
4. **CrÃ©er un notebook** de dÃ©monstration

### Ajouter un Nouveau ModÃ¨le ML

Dans `ml_service.py` ou `ml2_service.py`, ajouter :

```python
elif model_type == "xgboost":
    from xgboost import XGBClassifier
    model = XGBClassifier(random_state=42)
```

### Passer Ã  une Base de DonnÃ©es

1. Ajouter SQLAlchemy dans `requirements.txt`
2. CrÃ©er `app/database.py` avec configuration DB
3. CrÃ©er des modÃ¨les ORM dans `app/models/`
4. Remplacer les dictionnaires en mÃ©moire par des requÃªtes DB

---

## ğŸ“Š Performance et ScalabilitÃ©

### Ã‰tat Actuel (In-Memory)

**Avantages** :
- âœ… Rapide (pas d'I/O disque)
- âœ… Simple (pas de setup DB)
- âœ… IdÃ©al pour dÃ©veloppement/dÃ©monstration

**Limitations** :
- âŒ DonnÃ©es perdues au redÃ©marrage
- âŒ LimitÃ© par la RAM
- âŒ Pas de persistance
- âŒ Une seule instance (pas de scaling horizontal)

### AmÃ©liorations Possibles

1. **Persistance** : PostgreSQL + SQLAlchemy
2. **Cache** : Redis pour datasets frÃ©quents
3. **Files d'attente** : Celery pour long-running tasks (tuning)
4. **Object Storage** : S3/MinIO pour modÃ¨les et datasets
5. **Monitoring** : Prometheus + Grafana

---

## ğŸ§ª Tests

### Tests Unitaires

Fichier : `tests/test_api.py`

**Coverage actuelle** :
- âœ… Endpoints de base (/, /health)
- âœ… GÃ©nÃ©ration de datasets
- âœ… Pipeline de nettoyage (fit + transform)
- âœ… Gestion d'erreurs

**Lancer les tests** :
```bash
pytest tests/
```

---

## ğŸ³ Docker

### Image Docker

`Dockerfile` crÃ©e une image Python minimale avec :
- Python 3.11-slim
- Dependencies de requirements.txt
- Code de l'application

### Docker Compose

`docker-compose.yml` lance 2 services :
1. **api** : L'API FastAPI (port 8000)
2. **jupyter** : Serveur Jupyter (port 8888)

**Volumes montÃ©s** :
- Code synchronisÃ© en temps rÃ©el (dÃ©veloppement)
- ModÃ¨les et donnÃ©es persistants

---

## ğŸ“š Ressources

- [Documentation FastAPI](https://fastapi.tiangolo.com/)
- [Pydantic](https://docs.pydantic.dev/)
- [Scikit-learn](https://scikit-learn.org/)
- [Plotly](https://plotly.com/python/)

---

**Maintenu par** : Ayedesso  
**DerniÃ¨re mise Ã  jour** : 10 fÃ©vrier 2026
