{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1 - Clean : Nettoyage des Donn√©es\n",
    "\n",
    "Ce notebook d√©montre l'utilisation de l'API FastAPI pour le nettoyage de donn√©es.\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "1. G√©n√©rer un dataset avec des d√©fauts (missing, doublons, outliers)\n",
    "2. Obtenir un rapport qualit√©\n",
    "3. Fitter un pipeline de nettoyage\n",
    "4. Appliquer le nettoyage\n",
    "5. Comparer avant/apr√®s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'Python 3.12.3' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Configuration de l'API\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 1 : G√©n√©rer un dataset avec d√©fauts\n",
    "\n",
    "Utilisons l'endpoint  avec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©rer le dataset\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/dataset/generate\",\n",
    "    json={\n",
    "        \"phase\": \"clean\",\n",
    "        \"seed\": 42,\n",
    "        \"n\": 1000\n",
    "    }\n",
    ")\n",
    "\n",
    "data = response.json()\n",
    "dataset_id = data[\"meta\"][\"dataset_id\"]\n",
    "\n",
    "print(f\"Dataset ID: {dataset_id}\")\n",
    "print(f\"Nombre de lignes: {data['result']['n_rows']}\")\n",
    "print(f\"Colonnes: {data['result']['columns']}\")\n",
    "\n",
    "# Afficher un √©chantillon\n",
    "df_sample = pd.DataFrame(data['result']['data_sample'])\n",
    "df_sample.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 2 : Obtenir un rapport qualit√© (avant nettoyage)\n",
    "\n",
    "Utilisons  pour analyser les d√©fauts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir le rapport\n",
    "response = requests.get(f\"{BASE_URL}/clean/report/{dataset_id}\")\n",
    "report_data = response.json()\n",
    "\n",
    "report = report_data[\"report\"]\n",
    "\n",
    "print(\"üìä Rapport Qualit√© - AVANT nettoyage\n",
    "\")\n",
    "print(f\"Nombre total de lignes: {report['n_rows']}\")\n",
    "print(f\"Nombre de doublons: {report['duplicates']}\")\n",
    "print(\"\n",
    "Missing values par colonne:\")\n",
    "for col, stats in report['missing_values'].items():\n",
    "    print(f\"  {col}: {stats['count']} ({stats['rate']*100:.1f}%)\")\n",
    "\n",
    "print(\"\n",
    "Outliers par colonne:\")\n",
    "for col, stats in report['outliers'].items():\n",
    "    print(f\"  {col}: {stats['count']} ({stats['rate']*100:.1f}%)\")\n",
    "\n",
    "print(\"\n",
    "Types de donn√©es:\")\n",
    "for col, dtype in report['data_types'].items():\n",
    "    print(f\"  {col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 3 : Fitter un pipeline de nettoyage\n",
    "\n",
    "D√©finir les strat√©gies de nettoyage et apprendre le pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitter le pipeline\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/clean/fit\",\n",
    "    json={\n",
    "        \"meta\": {\n",
    "            \"dataset_id\": dataset_id\n",
    "        },\n",
    "        \"params\": {\n",
    "            \"impute_strategy\": \"mean\",\n",
    "            \"outlier_strategy\": \"clip\",\n",
    "            \"categorical_strategy\": \"one_hot\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "fit_data = response.json()\n",
    "cleaner_id = fit_data[\"result\"][\"cleaner_id\"]\n",
    "\n",
    "print(f\"‚úÖ Pipeline de nettoyage cr√©√©: {cleaner_id}\")\n",
    "print(\"\n",
    "R√®gles apprises:\")\n",
    "print(f\"  Impute values: {fit_data['report']['rules_learned']['impute_values_count']} colonnes\")\n",
    "print(f\"  Outlier bounds: {fit_data['report']['rules_learned']['outlier_bounds_count']} colonnes\")\n",
    "print(f\"  Categorical mappings: {fit_data['report']['rules_learned']['categorical_mappings_count']} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 4 : Appliquer le nettoyage\n",
    "\n",
    "Transformer les donn√©es avec le pipeline appris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la transformation\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/clean/transform\",\n",
    "    json={\n",
    "        \"meta\": {\n",
    "            \"dataset_id\": dataset_id\n",
    "        },\n",
    "        \"params\": {\n",
    "            \"cleaner_id\": cleaner_id\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "transform_data = response.json()\n",
    "cleaned_dataset_id = transform_data[\"result\"][\"processed_dataset_id\"]\n",
    "\n",
    "print(f\"‚úÖ Nettoyage appliqu√©: {cleaned_dataset_id}\")\n",
    "print(\"\n",
    "üìä Compteurs de nettoyage:\")\n",
    "counters = transform_data[\"report\"][\"counters\"]\n",
    "print(f\"  Lignes avant: {counters['rows_before']}\")\n",
    "print(f\"  Lignes apr√®s: {counters['rows_after']}\")\n",
    "print(f\"  Doublons supprim√©s: {counters['duplicates_removed']}\")\n",
    "print(\"\n",
    "  Missing values imput√©es:\")\n",
    "for col, count in counters['missing_imputed'].items():\n",
    "    print(f\"    {col}: {count}\")\n",
    "print(\"\n",
    "  Outliers trait√©s:\")\n",
    "for col, count in counters['outliers_treated'].items():\n",
    "    print(f\"    {col}: {count}\")\n",
    "\n",
    "# Afficher un √©chantillon nettoy√©\n",
    "df_clean = pd.DataFrame(transform_data['result']['data_sample'])\n",
    "print(\"\n",
    "‚úÖ √âchantillon de donn√©es nettoy√©es:\")\n",
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## √âtape 5 : Comparaison Avant/Apr√®s\n",
    "\n",
    "Visualiser l'am√©lioration de la qualit√© des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Rapport AVANT vs APR√àS\n",
    "\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "report_before = fit_data['report']['quality_before']\n",
    "report_after = transform_data['report']['report_after']\n",
    "\n",
    "print(f\"Lignes:  {report_before['n_rows']} ‚Üí {report_after['n_rows']}\")\n",
    "print(f\"Doublons: {report_before['duplicates']} ‚Üí {report_after['duplicates']}\")\n",
    "\n",
    "print(\"\n",
    "Missing values (taux):\")\n",
    "for col in report_before['missing_values'].keys():\n",
    "    if col in report_after['missing_values']:\n",
    "        before = report_before['missing_values'][col]['rate'] * 100\n",
    "        after = report_after['missing_values'][col]['rate'] * 100\n",
    "        print(f\"  {col}: {before:.1f}% ‚Üí {after:.1f}%\")\n",
    "\n",
    "print(\"\n",
    "‚úÖ Nettoyage termin√© avec succ√®s !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
